{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.client import PFClient\n",
    "\n",
    "pf = PFClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "data = \"./test_data.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chat flow\n",
    "chat_run = pf.run(\"./flow.flex.yaml\", data=data, stream=True)\n",
    "\n",
    "details = pf.get_details(chat_run)\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_correctness_run = pf.run(\"./evals/correctness/flow.flex.yaml\", data = data, run = chat_run, \n",
    "                                column_mapping= {\n",
    "                                    \"question\": \"${data.question}\", \n",
    "                                    \"answer\": \"${run.outputs.output}\", \n",
    "                                    \"groundtruth\": \"${data.ground_truth}\"},stream=True)\n",
    "\n",
    "details = pf.get_details(eval_correctness_run)\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.visualize([chat_run, eval_correctness_run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we try mistral instead\n",
    "import os\n",
    "os.environ[\"MODEL_PROVIDER\"] = \"mistral\"\n",
    "\n",
    "mistral_chat_run = pf.run(\"./flow.flex.yaml\", data=data, stream=True)\n",
    "\n",
    "details = pf.get_details(mistral_chat_run)\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_eval_correctness_run = pf.run(\"./evals/correctness/flow.flex.yaml\", data = data, run = chat_run, \n",
    "                                column_mapping= {\n",
    "                                    \"question\": \"${data.question}\", \n",
    "                                    \"answer\": \"${run.outputs.output}\", \n",
    "                                    \"groundtruth\": \"${data.ground_truth}\"},stream=True)\n",
    "\n",
    "details = pf.get_details(eval_correctness_run)\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.visualize([chat_run, eval_correctness_run, mistral_chat_run, mistral_eval_correctness_run])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
